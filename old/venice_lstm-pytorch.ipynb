{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np# linear algebra\n",
    "from numpy import nan\n",
    "from numpy import array\n",
    "#from mpl_toolkits.mplot3d import Axes3D\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt # plotting\n",
    "import os # accessing directory structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       wh  temp\n",
      "datetime                       \n",
      "2020-10-01 23:20:00  0.51  10.6\n",
      "2020-10-01 23:30:00  0.51  10.5\n",
      "2020-10-01 23:40:00  0.51  10.4\n",
      "2020-10-01 23:50:00  0.50  10.2\n",
      "2020-11-01 00:00:00  0.50  10.1\n"
     ]
    }
   ],
   "source": [
    "#already dropped NA's\n",
    "#sorted entries by date\n",
    "dataset = pd.read_csv('venice_new.csv', header=0, infer_datetime_format=True, parse_dates=['datetime'], index_col=['datetime'])\n",
    "\n",
    "print(dataset.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing data \n",
    "https://machinelearningmastery.com/how-to-load-and-explore-household-electricity-usage-data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(dataset_19[month].to_string())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem framing\n",
    "I guess we want to for example predict the temperature and water level for the next month\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach\n",
    "Classical linear methods include techniques are very effective for univariate time series forecasting. SARIMA\n",
    "or\n",
    "Deep Learning CNN LSTM and ConvLSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try DL LSTM of course \n",
    "https://machinelearningmastery.com/how-to-develop-lstm-models-for-multi-step-time-series-forecasting-of-household-power-consumption/\n",
    "#maybe group the data by day\n",
    "#then split the data into week chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "daily_groups = dataset.resample('D')\n",
    "daily_data = daily_groups.mean()\n",
    "#print(daily_data.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Even though there are only a few periods where there are daily measurements. I will interpolate the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlier Detection and Imputation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Interpolate the dataset based on previous/next values..\n",
    "#This works super good. it's like a gradual inference of the data points\n",
    "def impute_interpolate(dataset, col):\n",
    "    dataset[col] = dataset[col].interpolate()\n",
    "    # And fill the initial data points if needed:\n",
    "    dataset[col] = dataset[col].fillna(method='bfill')\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data= impute_interpolate(dataset=dataset, col='wh')\n",
    "data= impute_interpolate(dataset=data, col='temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "daily_data= data\n",
    "#print(daily_data.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ok so basically using the kalman diter didnt have much of an effect, at least based on v rough visual inspection.\n",
    "#Mostly smoothes values. Could have also used kalman instead of interpolation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data for Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4014\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_size = round(len(dataset)*0.3) \n",
    "print(test_data_size)\n",
    "\n",
    "train_data = dataset[:-test_data_size]\n",
    "test_data = dataset[-test_data_size:]\n",
    "\n",
    "#train_data= np.array(train_data)\n",
    "#test_data= np.array(test_data)\n",
    "\n",
    "train_data.shape\n",
    "type(train_data)\n",
    "#print(train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import seaborn as sns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9365, 2])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert to numpy and then to tensor\n",
    "\n",
    "tmp = train_data.values\n",
    "train_data = torch.from_numpy(tmp).float()\n",
    "train_data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.4500, 16.4000],\n",
      "        [ 0.4600, 16.4000],\n",
      "        [ 0.4700, 16.3000],\n",
      "        [ 0.4800, 16.3000],\n",
      "        [ 0.4900, 16.2000]])\n"
     ]
    }
   ],
   "source": [
    "print(train_data[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get weeks with forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now I will try to do it in Pytorch\n",
    "https://stackabuse.com/time-series-prediction-using-lstm-with-pytorch-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#convert to tensor \n",
    "#train_data_normalized = torch.FloatTensor(train).view(-1) #I think the flattenign was not necessart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#returns a list of tuples\n",
    "def create_inout_sequences(input_data, tw):\n",
    "    inout_seq = []\n",
    "    L = len(input_data)\n",
    "    for i in range(L-tw):\n",
    "        train_seq = input_data[i:i+tw]\n",
    "        train_label = input_data[i+tw:i+tw+1]  # the label is sort o f the predicted. so all of of the predictions become one time longet now? \n",
    "        inout_seq.append((train_seq ,train_label))  #tuple containing the 7 days values and the next value \n",
    "    return inout_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_window=7\n",
    "train_inout_seq = create_inout_sequences(train_data, train_window) #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(tensor([[0.6200, 9.2000],\n",
      "        [0.6200, 9.2000],\n",
      "        [0.6200, 9.1000],\n",
      "        [0.6200, 9.1000],\n",
      "        [0.6200, 9.1000],\n",
      "        [0.6200, 9.2000],\n",
      "        [0.6100, 9.2000]]), tensor([[0.6100, 9.2000]])), (tensor([[0.6200, 9.2000],\n",
      "        [0.6200, 9.1000],\n",
      "        [0.6200, 9.1000],\n",
      "        [0.6200, 9.1000],\n",
      "        [0.6200, 9.2000],\n",
      "        [0.6100, 9.2000],\n",
      "        [0.6100, 9.2000]]), tensor([[0.6100, 9.3000]]))]\n"
     ]
    }
   ],
   "source": [
    "print(train_inout_seq[-2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size=2, hidden_layer_size=100, output_size=2):\n",
    "        super().__init__()\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_layer_size)\n",
    "\n",
    "        self.linear = nn.Linear(hidden_layer_size,2 ) #output_size\n",
    "\n",
    "        self.hidden_cell = (torch.zeros(1,1,self.hidden_layer_size),\n",
    "                            torch.zeros(1,1,self.hidden_layer_size))\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        input=input_seq.view(len(input_seq), 1,-1)\n",
    "       # print(input_seq)\n",
    "        lstm_out, self.hidden_cell = self.lstm(input, self.hidden_cell)\n",
    "        lstm_out_new= lstm_out.view(input_seq.shape[0],-1)\n",
    "        predictions = self.linear(lstm_out_new)\n",
    "       # print(predictions)\n",
    "        predictions=predictions[-1]\n",
    "        predictions=predictions.view(1,2) # or maybe should squeeze?\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LSTM()\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   1 loss: 0.00267717\n",
      "epoch:  19 loss: 0.0269205980\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "\n",
    "for i in range(epochs):\n",
    "    for seq, labels in train_inout_seq:\n",
    "       # seq=seq.float()\n",
    "      #  labels= labels.float()\n",
    "        optimizer.zero_grad()\n",
    "        model.hidden_cell = (torch.zeros(1, 1, model.hidden_layer_size),\n",
    "                        torch.zeros(1, 1, model.hidden_layer_size))\n",
    "\n",
    "        y_pred = model(seq)\n",
    "        #print(y_pred)\n",
    "        #print(labels.shape)\n",
    "\n",
    "        single_loss = loss_function(y_pred, labels)\n",
    "        single_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if i%25 == 1:\n",
    "        print(f'epoch: {i:3} loss: {single_loss.item():10.8f}')\n",
    "\n",
    "print(f'epoch: {i:3} loss: {single_loss.item():10.10f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6200, 9.1000],\n",
      "        [0.6200, 9.1000],\n",
      "        [0.6200, 9.1000],\n",
      "        [0.6200, 9.2000],\n",
      "        [0.6100, 9.2000],\n",
      "        [0.6100, 9.2000],\n",
      "        [0.6100, 9.3000]])\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "#get the last 7 values from the training window\n",
    "train_window=7\n",
    "fut_pred = 7\n",
    "\n",
    "test_inputs = train_data[-train_window:]#.tolist()\n",
    "test_inputs_list= test_inputs.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "for i in range(fut_pred):\n",
    "    seq = torch.FloatTensor(test_inputs_list[-train_window:])\n",
    "    seq=seq.float()\n",
    "    #print(seq)\n",
    "    with torch.no_grad():\n",
    "        model.hidden = (torch.zeros(1, 1, model.hidden_layer_size),\n",
    "                        torch.zeros(1, 1, model.hidden_layer_size))\n",
    "        pred= model(seq).squeeze().tolist()  #squeeze otherwise double klammer\n",
    "        test_inputs_list.append(pred)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.6200000047683716, 9.100000381469727], [0.6200000047683716, 9.100000381469727], [0.6200000047683716, 9.100000381469727], [0.6200000047683716, 9.199999809265137], [0.6100000143051147, 9.199999809265137], [0.6100000143051147, 9.199999809265137], [0.6100000143051147, 9.300000190734863], [0.6054630875587463, 13.492826461791992], [0.6063072085380554, 13.503717422485352], [0.6063224077224731, 13.504024505615234], [0.6063266396522522, 13.50406265258789], [0.6063289046287537, 13.504083633422852], [0.6063303351402283, 13.504095077514648], [0.6063313484191895, 13.50410270690918], [0.6063320636749268, 13.504107475280762], [0.6063323020935059, 13.504108428955078], [0.6063323020935059, 13.504108428955078], [0.6063322424888611, 13.504108428955078], [0.6063323020935059, 13.504108428955078], [0.6063323020935059, 13.504108428955078], [0.6063323020935059, 13.504108428955078]]\n"
     ]
    }
   ],
   "source": [
    "print(test_inputs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected np.ndarray (got builtin_function_or_method)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-275-a71c344cd1f3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtmp2\u001b[0m\u001b[1;33m=\u001b[0m  \u001b[0mtest_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtest_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mte\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#torch.FloatTensor(test_data[:fut_pred])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected np.ndarray (got builtin_function_or_method)"
     ]
    }
   ],
   "source": [
    "tmp2=  test_data.values\n",
    "test_data = torch.from_numpy(tmp2).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6100, 9.2000],\n",
      "        [0.5900, 9.1000],\n",
      "        [0.5700, 9.1000],\n",
      "        [0.5600, 9.1000],\n",
      "        [0.5400, 9.0000],\n",
      "        [0.5300, 9.0000],\n",
      "        [0.5100, 9.0000]])\n"
     ]
    }
   ],
   "source": [
    "actual=test_data[:fut_pred]\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6063, 13.5041],\n",
       "        [ 0.6063, 13.5041],\n",
       "        [ 0.6063, 13.5041],\n",
       "        [ 0.6063, 13.5041],\n",
       "        [ 0.6063, 13.5041],\n",
       "        [ 0.6063, 13.5041],\n",
       "        [ 0.6063, 13.5041]])"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred= torch.FloatTensor(test_inputs_list[-fut_pred:])\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('wh and temp vs week')\n",
    "plt.ylabel('Value')\n",
    "plt.grid(True)\n",
    "plt.autoscale(axis='x', tight=True)\n",
    "x= range(7)\n",
    "plt.plot(x,actual)\n",
    "plt.plot(x,pred)\n",
    "plt.show()\n",
    "\n",
    "#ok so according to this. the actual values were a bit lower for both the wh and the temperature \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
